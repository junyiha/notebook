---
category: NVIDIA
date: 2025-02-18 09:00:00 +0800
layout: post
title: CUDA å¸¸è§å‡½æ•°
tag: CUDA
---
## ç®€ä»‹

+ CUDA ä¸­å¸¸è§çš„å‡½æ•°

<!--more-->

## cudaSetDevice() å‡½æ•° è¯¦è§£

### `cudaSetDevice()` å‡½æ•°è¯¦è§£

#### **1. ä½œç”¨**
`cudaSetDevice(int device)` ç”¨äºè®¾ç½®å½“å‰ CPU çº¿ç¨‹è¦ä½¿ç”¨çš„ GPU è®¾å¤‡ã€‚åœ¨ä¸€ä¸ªç³»ç»Ÿä¸­å¯èƒ½æœ‰å¤šä¸ª GPUï¼Œæ­¤å‡½æ•°å¯ä»¥è®©ç¨‹åºé€‰æ‹©ç‰¹å®šçš„ GPU è¿›è¡Œè®¡ç®—ã€‚

#### **2. è¯­æ³•**
```cpp
cudaError_t cudaSetDevice(int device);
```
- `device`ï¼šè¦é€‰æ‹©çš„ GPU è®¾å¤‡çš„ç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰ã€‚
- è¿”å›å€¼ï¼šè¿”å› `cudaError_t` ç±»å‹çš„é”™è¯¯ç ï¼Œè‹¥æˆåŠŸè¿”å› `cudaSuccess`ã€‚

#### **3. ç›¸å…³è¯´æ˜**
- å¿…é¡»åœ¨è°ƒç”¨ä»»ä½• CUDA APIï¼ˆå¦‚ `cudaMalloc()`ã€`cudaMemcpy()`ï¼‰ä¹‹å‰è°ƒç”¨ `cudaSetDevice()`ï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´é”™è¯¯æˆ–å½±å“æ€§èƒ½ã€‚
- æ¯ä¸ª CPU çº¿ç¨‹åªèƒ½ç»‘å®šä¸€ä¸ª GPU è®¾å¤‡ï¼Œå› æ­¤ `cudaSetDevice()` ä»…å½±å“å½“å‰çº¿ç¨‹ã€‚
- å¦‚æœæ²¡æœ‰è°ƒç”¨ `cudaSetDevice()`ï¼ŒCUDA è¿è¡Œæ—¶é»˜è®¤é€‰æ‹© `device 0`ã€‚
- éœ€è¦ç¡®ä¿ `device` å€¼åœ¨å¯ç”¨çš„ GPU èŒƒå›´å†…ï¼ˆå¯ç”¨ `cudaGetDeviceCount()` è·å– GPU æ€»æ•°ï¼‰ã€‚

#### **4. ä»£ç ç¤ºä¾‹**
```cpp
#include <cuda_runtime.h>
#include <iostream>

int main() {
    int deviceCount;
    cudaGetDeviceCount(&deviceCount);
    if (deviceCount == 0) {
        std::cerr << "No CUDA devices available." << std::endl;
        return -1;
    }

    int deviceId = 1; // å‡è®¾æƒ³ä½¿ç”¨ç¬¬ 1 å— GPU
    if (deviceId >= deviceCount) {
        std::cerr << "Invalid device ID." << std::endl;
        return -1;
    }

    cudaError_t err = cudaSetDevice(deviceId);
    if (err != cudaSuccess) {
        std::cerr << "cudaSetDevice failed: " << cudaGetErrorString(err) << std::endl;
        return -1;
    }

    std::cout << "Using GPU " << deviceId << std::endl;

    return 0;
}
```

#### **5. è·å–å½“å‰è®¾å¤‡**
å¯ä»¥ä½¿ç”¨ `cudaGetDevice()` è·å–å½“å‰çº¿ç¨‹ç»‘å®šçš„ GPUï¼š
```cpp
int currentDevice;
cudaGetDevice(&currentDevice);
std::cout << "Current device: " << currentDevice << std::endl;
```

#### **6. çº¿ç¨‹ä¸è®¾å¤‡çš„å…³ç³»**
- åœ¨ **å•çº¿ç¨‹ç¨‹åº** ä¸­ï¼Œæ¯ä¸ª CPU çº¿ç¨‹åªèƒ½ä½¿ç”¨ä¸€ä¸ª GPUã€‚
- åœ¨ **å¤šçº¿ç¨‹ç¨‹åº** ä¸­ï¼Œä¸åŒçš„ CPU çº¿ç¨‹å¯ä»¥ç»‘å®šåˆ°ä¸åŒçš„ GPU ä»¥å¹¶è¡Œè®¡ç®—ï¼Œä½†ä¸€ä¸ªçº¿ç¨‹ä¸èƒ½åŒæ—¶ä½¿ç”¨å¤šä¸ª GPUã€‚

#### **7. å¯èƒ½çš„é”™è¯¯**
| é”™è¯¯ä»£ç                       | è¯´æ˜                                         |
| ----------------------------- | -------------------------------------------- |
| `cudaErrorInvalidDevice`      | `device` å·è¶…å‡º GPU æ•°é‡èŒƒå›´                 |
| `cudaErrorSetOnActiveProcess` | å½“å‰è¿›ç¨‹å·²ç»ä½¿ç”¨äº†å¦ä¸€ä¸ª GPUï¼ˆåœ¨æŸäº›æƒ…å†µä¸‹ï¼‰ |

#### **8. ç»“åˆ `cudaGetDeviceCount()`**
åœ¨è°ƒç”¨ `cudaSetDevice()` ä¹‹å‰ï¼Œå»ºè®®ä½¿ç”¨ `cudaGetDeviceCount()` ç¡®ä¿ `device` å€¼åˆæ³•ï¼š
```cpp
int deviceCount;
cudaGetDeviceCount(&deviceCount);
if (deviceCount > 0) {
    cudaSetDevice(0); // é€‰æ‹©ç¬¬ä¸€ä¸ª GPU
}
```

#### **9. æ€»ç»“**
- `cudaSetDevice()` ç”¨äºé€‰æ‹© GPUï¼Œå¿…é¡»åœ¨ CUDA ç›¸å…³ API è°ƒç”¨å‰ä½¿ç”¨ã€‚
- ä»…å¯¹å½“å‰ CPU çº¿ç¨‹ç”Ÿæ•ˆã€‚
- åœ¨å¤š GPU ç¯å¢ƒä¸‹ï¼Œå¯ç»“åˆ `cudaGetDeviceCount()` å’Œ `cudaGetDevice()` ç¡®ä¿é€‰æ‹©æœ‰æ•ˆè®¾å¤‡ã€‚

è¿™æ ·å¯ä»¥æœ‰æ•ˆç®¡ç†å¤š GPU è®¡ç®—èµ„æºï¼Œæé«˜ CUDA ç¨‹åºçš„çµæ´»æ€§å’Œæ€§èƒ½ã€‚ ğŸš€

## cudaMalloc() å‡½æ•° è¯¦è§£

# **`cudaMalloc()` å‡½æ•°è¯¦è§£**

## **1. ä½œç”¨**
`cudaMalloc()` ç”¨äºåœ¨ GPU è®¾å¤‡ï¼ˆDeviceï¼‰ä¸Šåˆ†é…å…¨å±€å†…å­˜ï¼ˆGlobal Memoryï¼‰ã€‚è¿™æ˜¯ CUDA ä¸­æœ€åŸºç¡€çš„å†…å­˜ç®¡ç†å‡½æ•°ä¹‹ä¸€ã€‚

---

## **2. è¯­æ³•**
```cpp
cudaError_t cudaMalloc(void** devPtr, size_t size);
```
### **å‚æ•°**
- `devPtr`ï¼šæŒ‡å‘å­˜å‚¨è®¾å¤‡å†…å­˜åœ°å€çš„æŒ‡é’ˆå˜é‡ï¼ˆå³æŒ‡å‘ `void*` çš„æŒ‡é’ˆï¼‰ã€‚
- `size`ï¼šè¦åˆ†é…çš„å†…å­˜å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚

### **è¿”å›å€¼**
- **`cudaSuccess`ï¼ˆ0ï¼‰**ï¼šåˆ†é…æˆåŠŸã€‚
- **å…¶ä»–é”™è¯¯ç **ï¼ˆå¦‚ `cudaErrorMemoryAllocation`ï¼‰ï¼šåˆ†é…å¤±è´¥ã€‚

---

## **3. ä½¿ç”¨ç¤ºä¾‹**
### **(1) åœ¨ GPU è®¾å¤‡ä¸Šåˆ†é…å†…å­˜**
```cpp
#include <cuda_runtime.h>
#include <iostream>

int main() {
    int* d_ptr;  // è®¾å¤‡æŒ‡é’ˆ
    size_t size = 100 * sizeof(int);  // åˆ†é… 100 ä¸ª int

    cudaError_t err = cudaMalloc((void**)&d_ptr, size);
    if (err != cudaSuccess) {
        std::cerr << "cudaMalloc failed: " << cudaGetErrorString(err) << std::endl;
        return -1;
    }

    std::cout << "Memory allocated on GPU." << std::endl;

    // é‡Šæ”¾è®¾å¤‡å†…å­˜
    cudaFree(d_ptr);

    return 0;
}
```

---

## **4. ç›¸å…³æ³¨æ„äº‹é¡¹**
### **(1) è®¾å¤‡æŒ‡é’ˆä¸èƒ½ç›´æ¥åœ¨ä¸»æœºï¼ˆCPUï¼‰ç«¯è®¿é—®**
```cpp
int* d_ptr;
cudaMalloc((void**)&d_ptr, 100 * sizeof(int));
std::cout << *d_ptr << std::endl;  // âŒ é”™è¯¯ï¼è®¾å¤‡æŒ‡é’ˆä¸èƒ½ç›´æ¥è§£å¼•ç”¨
```
**æ­£ç¡®åšæ³•**ï¼šä½¿ç”¨ `cudaMemcpy()` å°†æ•°æ®æ‹·è´åˆ°ä¸»æœºï¼š
```cpp
int h_val;
cudaMemcpy(&h_val, d_ptr, sizeof(int), cudaMemcpyDeviceToHost);
std::cout << h_val << std::endl;
```

---

### **(2) è®¾å¤‡å†…å­˜éœ€è¦æ‰‹åŠ¨é‡Šæ”¾**
- ä½¿ç”¨ `cudaFree()` é‡Šæ”¾å†…å­˜ï¼š
```cpp
cudaFree(d_ptr);
```
- å¦‚æœå¿˜è®°é‡Šæ”¾ï¼Œä¼šå¯¼è‡´ **æ˜¾å­˜æ³„æ¼ï¼ˆMemory Leakï¼‰**ã€‚

---

### **(3) æ£€æŸ¥ `cudaMalloc()` æ˜¯å¦æˆåŠŸ**
- **å¯èƒ½çš„é”™è¯¯**
  - `cudaErrorMemoryAllocation`ï¼šæ˜¾å­˜ä¸è¶³
  - `cudaErrorInvalidValue`ï¼š`size` ä¸º 0
  - `cudaErrorInvalidDevicePointer`ï¼šä¼ å…¥çš„æŒ‡é’ˆéæ³•
- **å»ºè®®ï¼šå§‹ç»ˆæ£€æŸ¥è¿”å›å€¼**
```cpp
if (cudaMalloc((void**)&d_ptr, size) != cudaSuccess) {
    std::cerr << "Memory allocation failed!" << std::endl;
}
```

---

### **(4) è®¡ç®—è®¾å¤‡å†…å­˜çš„ä½¿ç”¨æƒ…å†µ**
- `cudaMemGetInfo()` å¯ç”¨äºæŸ¥è¯¢ GPU å‰©ä½™å†…å­˜ï¼š
```cpp
size_t freeMem, totalMem;
cudaMemGetInfo(&freeMem, &totalMem);
std::cout << "Free memory: " << freeMem / (1024 * 1024) << " MB, "
          << "Total memory: " << totalMem / (1024 * 1024) << " MB" << std::endl;
```

---

### **(5) å¤š GPU ç¯å¢ƒ**
- `cudaMalloc()` ä»…åœ¨å½“å‰è®¾å¤‡ä¸Šåˆ†é…å†…å­˜ã€‚
- è‹¥ä½¿ç”¨å¤š GPUï¼Œå¯å…ˆè°ƒç”¨ `cudaSetDevice(deviceId)` åˆ‡æ¢ GPUï¼š
```cpp
cudaSetDevice(1);  // é€‰æ‹© GPU 1
cudaMalloc((void**)&d_ptr, size);
```

---

## **5. `cudaMalloc()` ä¸å…¶ä»– CUDA å†…å­˜ç®¡ç†å‡½æ•°çš„æ¯”è¾ƒ**
| å‡½æ•°                  | ä½œç”¨                             | é€‚ç”¨åœºæ™¯            | é‡Šæ”¾æ–¹æ³•         |
| --------------------- | -------------------------------- | ------------------- | ---------------- |
| `cudaMalloc()`        | è®¾å¤‡å…¨å±€å†…å­˜åˆ†é…                 | GPU è®¡ç®—æ•°æ®å­˜å‚¨    | `cudaFree()`     |
| `cudaMallocHost()`    | ä¸»æœºé¡µé”å®šå†…å­˜ï¼ˆå¯ç”¨äºå¼‚æ­¥æ‹·è´ï¼‰ | `cudaMemcpyAsync()` | `cudaFreeHost()` |
| `cudaMallocManaged()` | ç»Ÿä¸€å†…å­˜ï¼ˆä¸»æœºå’Œè®¾å¤‡å…±äº«ï¼‰       | ç»Ÿä¸€å†…å­˜ç¼–ç¨‹        | `cudaFree()`     |
| `cudaMallocPitch()`   | 2D æ•°ç»„åˆ†é…ï¼Œä¼˜åŒ–å¯¹é½            | å¤„ç†å›¾åƒç­‰ 2D æ•°æ®  | `cudaFree()`     |

---

## **6. æ€»ç»“**
- `cudaMalloc()` åœ¨ GPU ä¸Šåˆ†é…å…¨å±€å†…å­˜ï¼Œè¿”å›è®¾å¤‡æŒ‡é’ˆã€‚
- ä¸èƒ½ç›´æ¥è®¿é—®è®¾å¤‡æŒ‡é’ˆï¼Œéœ€è¦ä½¿ç”¨ `cudaMemcpy()` è¿›è¡Œæ•°æ®ä¼ è¾“ã€‚
- éœ€è¦æ‰‹åŠ¨é‡Šæ”¾ `cudaFree()`ï¼Œå¦åˆ™ä¼šå¯¼è‡´æ˜¾å­˜æ³„æ¼ã€‚
- åœ¨å¤š GPU ç¯å¢ƒä¸‹ï¼Œåº”å…ˆè°ƒç”¨ `cudaSetDevice()` é€‰æ‹©ç›®æ ‡ GPUã€‚

åˆç†ä½¿ç”¨ `cudaMalloc()` è¿›è¡Œæ˜¾å­˜ç®¡ç†ï¼Œå¯ä»¥æé«˜ CUDA ç¨‹åºçš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚ ğŸš€

## cudaStreamCreate() å‡½æ•° è¯¦è§£

# **`cudaStreamCreate()` å‡½æ•°è¯¦è§£**

## **1. ä½œç”¨**
`cudaStreamCreate()` ç”¨äºåˆ›å»º CUDA **æµï¼ˆStreamï¼‰**ï¼Œæµæ˜¯ä¸€ç§å¼‚æ­¥æ‰§è¡Œçš„é˜Ÿåˆ—ï¼Œå¯ä»¥åœ¨åŒä¸€ GPU ä¸ŠåŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œå®ç° **å¹¶è¡Œè®¡ç®—** å’Œ **å¼‚æ­¥æ‰§è¡Œ**ã€‚

---

## **2. è¯­æ³•**
```cpp
cudaError_t cudaStreamCreate(cudaStream_t* pStream);
```
### **å‚æ•°**
- `pStream`ï¼šæŒ‡å‘ `cudaStream_t` ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºå­˜å‚¨åˆ›å»ºçš„æµçš„å¥æŸ„ã€‚

### **è¿”å›å€¼**
- `cudaSuccess`ï¼šæµåˆ›å»ºæˆåŠŸã€‚
- å…¶ä»– `cudaError_t` é”™è¯¯ç ï¼šåˆ›å»ºå¤±è´¥ï¼Œä¾‹å¦‚ **å†…å­˜ä¸è¶³** æˆ– **CUDA ä¸Šä¸‹æ–‡é—®é¢˜**ã€‚

---

## **3. ä½¿ç”¨ç¤ºä¾‹**
### **(1) åˆ›å»ºå¹¶ä½¿ç”¨ CUDA æµ**
```cpp
#include <cuda_runtime.h>
#include <iostream>

int main() {
    cudaStream_t stream;
    cudaError_t err = cudaStreamCreate(&stream);
    
    if (err != cudaSuccess) {
        std::cerr << "cudaStreamCreate failed: " << cudaGetErrorString(err) << std::endl;
        return -1;
    }

    std::cout << "CUDA Stream created successfully!" << std::endl;

    // ä½¿ç”¨æµè¿›è¡Œå¼‚æ­¥è®¡ç®—ï¼ˆç¤ºä¾‹ä»£ç ç•¥ï¼‰

    // é‡Šæ”¾æµ
    cudaStreamDestroy(stream);

    return 0;
}
```

---

## **4. ç›¸å…³å‡½æ•°**
### **(1) `cudaStreamDestroy()` - é”€æ¯ CUDA æµ**
æ¯ä¸ªåˆ›å»ºçš„ CUDA æµåœ¨ä½¿ç”¨ååº”å½“é‡Šæ”¾ï¼š
```cpp
cudaStreamDestroy(stream);
```

### **(2) `cudaMemcpyAsync()` - å¼‚æ­¥æ‹·è´**
æµå¯ä»¥ä¸ `cudaMemcpyAsync()` ç»“åˆï¼Œå®ç° **å¼‚æ­¥æ•°æ®æ‹·è´**ï¼š
```cpp
int* d_data;
int h_data[100];
cudaMalloc((void**)&d_data, 100 * sizeof(int));

cudaMemcpyAsync(d_data, h_data, 100 * sizeof(int), cudaMemcpyHostToDevice, stream);
```

### **(3) `cudaStreamSynchronize()` - ç­‰å¾…æµå®Œæˆ**
ä½¿ç”¨ `cudaStreamSynchronize()` å¯ä»¥ç­‰å¾…ç‰¹å®šæµä¸­çš„ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼š
```cpp
cudaStreamSynchronize(stream);
```

---

## **5. CUDA æµçš„ç‰¹ç‚¹**
### **(1) é»˜è®¤æµï¼ˆ`cudaStream_t(0)`ï¼‰**
- å¦‚æœ **ä¸æŒ‡å®šæµ**ï¼ŒCUDA å†…æ ¸å’Œ `cudaMemcpy()` è¿è¡Œåœ¨ **é»˜è®¤æµï¼ˆé»˜è®¤é˜Ÿåˆ—ï¼‰** ä¸­ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œï¼š
```cpp
cudaMemcpy(d_data, h_data, 100 * sizeof(int), cudaMemcpyHostToDevice);
kernel<<<grid, block>>>(d_data);
cudaMemcpy(h_data, d_data, 100 * sizeof(int), cudaMemcpyDeviceToHost);
```
- è¿™äº›æ“ä½œä¼š **æŒ‰é¡ºåºæ‰§è¡Œ**ï¼Œä¸‹ä¸€ä¸ªä»»åŠ¡å¿…é¡»ç­‰å¾…ä¸Šä¸€ä¸ªä»»åŠ¡å®Œæˆã€‚

### **(2) ç”¨æˆ·å®šä¹‰æµï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰**
- ä½¿ç”¨ `cudaStreamCreate()` åˆ›å»º **å¤šä¸ªæµ**ï¼Œå¯åœ¨åŒä¸€ GPU è®¾å¤‡ä¸ŠåŒæ—¶æ‰§è¡Œ **å¤šä¸ªä»»åŠ¡**ï¼š
```cpp
cudaStream_t stream1, stream2;
cudaStreamCreate(&stream1);
cudaStreamCreate(&stream2);

// åœ¨ stream1 ä¸­æ‰§è¡Œå†…å­˜æ‹·è´
cudaMemcpyAsync(d_data1, h_data1, size, cudaMemcpyHostToDevice, stream1);
// åœ¨ stream2 ä¸­æ‰§è¡Œä¸åŒçš„ä»»åŠ¡
cudaMemcpyAsync(d_data2, h_data2, size, cudaMemcpyHostToDevice, stream2);

// ç­‰å¾…ä¸¤ä¸ªæµå®Œæˆ
cudaStreamSynchronize(stream1);
cudaStreamSynchronize(stream2);

// é‡Šæ”¾æµ
cudaStreamDestroy(stream1);
cudaStreamDestroy(stream2);
```
åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ**æ•°æ®æ‹·è´å’Œè®¡ç®—å¯ä»¥å¹¶è¡Œæ‰§è¡Œ**ï¼Œæé«˜ GPU åˆ©ç”¨ç‡ã€‚

---

## **6. ä½¿ç”¨å¤šä¸ª CUDA æµçš„åº”ç”¨åœºæ™¯**
| åœºæ™¯                   | è¯´æ˜                                                   |
| ---------------------- | ------------------------------------------------------ |
| **æ•°æ®æ‹·è´ä¸è®¡ç®—é‡å ** | `cudaMemcpyAsync()` å’Œ Kernel åœ¨ä¸åŒæµä¸­æ‰§è¡Œï¼Œæé«˜æ•ˆç‡ |
| **å¤š Kernel å¹¶è¡Œæ‰§è¡Œ** | å¤šä¸ª Kernel ä»»åŠ¡æ”¾å…¥ä¸åŒæµï¼Œæé«˜è®¡ç®—ååé‡             |
| **å¤šçº¿ç¨‹ä»»åŠ¡è°ƒåº¦**     | åœ¨å¤šçº¿ç¨‹ç¨‹åºä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹ç®¡ç†ä¸€ä¸ª CUDA æµ               |

---

## **7. `cudaStreamCreate()` å¯èƒ½çš„é”™è¯¯**
| é”™è¯¯ç                          | è¯´æ˜                    |
| ------------------------------ | ----------------------- |
| `cudaErrorInvalidValue`        | `pStream` ä¸ºç©ºæŒ‡é’ˆ      |
| `cudaErrorMemoryAllocation`    | å†…å­˜ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºæµ    |
| `cudaErrorInitializationError` | CUDA è¿è¡Œæ—¶æœªæ­£ç¡®åˆå§‹åŒ– |

---

## **8. æ€»ç»“**
- `cudaStreamCreate()` åˆ›å»º **CUDA æµ**ï¼Œç”¨äºå¼‚æ­¥æ‰§è¡Œä»»åŠ¡ã€‚
- ä»»åŠ¡å¯ä½¿ç”¨ `cudaMemcpyAsync()` æˆ– `cudaLaunchKernel()` æäº¤åˆ°ç‰¹å®šæµã€‚
- ä½¿ç”¨ `cudaStreamSynchronize()` ç­‰å¾…æµå®Œæˆï¼Œä½¿ç”¨ `cudaStreamDestroy()` é‡Šæ”¾èµ„æºã€‚
- é€‚ç”¨äº **æ•°æ®ä¼ è¾“ä¸è®¡ç®—é‡å ã€Kernel å¹¶è¡Œæ‰§è¡Œã€å¤šçº¿ç¨‹ä»»åŠ¡è°ƒåº¦** ç­‰åœºæ™¯ã€‚

åˆç†ä½¿ç”¨ CUDA æµï¼Œå¯ä»¥ **æå‡ GPU å¹¶è¡Œè®¡ç®—æ•ˆç‡**ï¼ŒåŠ é€Ÿæ·±åº¦å­¦ä¹ ã€ç§‘å­¦è®¡ç®—ç­‰åº”ç”¨ï¼ğŸš€

## cudaMemcpyAsync() å‡½æ•° è¯¦è§£

# **`cudaMemcpyAsync()` å‡½æ•°è¯¦è§£**

## **1. ä½œç”¨**
`cudaMemcpyAsync()` ç”¨äºåœ¨ **ä¸»æœºï¼ˆHostï¼‰** å’Œ **è®¾å¤‡ï¼ˆDeviceï¼‰** ä¹‹é—´è¿›è¡Œ **å¼‚æ­¥** æ•°æ®æ‹·è´ï¼Œä¸ `cudaMemcpy()` ä¸åŒï¼Œå®ƒä¸ä¼šé˜»å¡ CPUï¼Œè€Œæ˜¯å°†æ‹·è´ä»»åŠ¡æ”¾å…¥æŒ‡å®šçš„ **CUDA æµï¼ˆStreamï¼‰** ä¸­ï¼Œä»è€Œå®ç° **æ•°æ®ä¼ è¾“ä¸è®¡ç®—çš„é‡å **ï¼Œæé«˜ GPU è®¡ç®—æ•ˆç‡ã€‚

---

## **2. è¯­æ³•**
```cpp
cudaError_t cudaMemcpyAsync(void* dst, const void* src, size_t count, cudaMemcpyKind kind, cudaStream_t stream);
```
### **å‚æ•°**
- `dst`ï¼šç›®æ ‡åœ°å€ï¼ˆå¯ä»¥æ˜¯ä¸»æœºæˆ–è®¾å¤‡å†…å­˜ï¼‰ã€‚
- `src`ï¼šæºåœ°å€ï¼ˆå¯ä»¥æ˜¯ä¸»æœºæˆ–è®¾å¤‡å†…å­˜ï¼‰ã€‚
- `count`ï¼šæ‹·è´çš„æ•°æ®å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰ã€‚
- `kind`ï¼šæ•°æ®æ‹·è´çš„æ–¹å‘ï¼Œ`cudaMemcpyKind` æšä¸¾å€¼ï¼š
  - `cudaMemcpyHostToDevice`ï¼ˆHâ†’Dï¼‰ï¼šä»ä¸»æœºæ‹·è´åˆ°è®¾å¤‡
  - `cudaMemcpyDeviceToHost`ï¼ˆDâ†’Hï¼‰ï¼šä»è®¾å¤‡æ‹·è´åˆ°ä¸»æœº
  - `cudaMemcpyDeviceToDevice`ï¼ˆDâ†’Dï¼‰ï¼šåœ¨è®¾å¤‡å†…å­˜ä¹‹é—´æ‹·è´
  - `cudaMemcpyHostToHost`ï¼ˆHâ†’Hï¼‰ï¼šåœ¨ä¸»æœºå†…å­˜ä¹‹é—´æ‹·è´
- `stream`ï¼šæŒ‡å®š CUDA **æµ**ï¼Œæ•°æ®æ‹·è´ä»»åŠ¡å°†åœ¨è¯¥æµä¸­æ‰§è¡Œï¼ˆå¯ä½¿ç”¨ `0` ä»£è¡¨ **é»˜è®¤æµ**ï¼‰ã€‚

### **è¿”å›å€¼**
- **`cudaSuccess`**ï¼šæ‹·è´æˆåŠŸã€‚
- å…¶ä»– `cudaError_t` é”™è¯¯ç ï¼šå¦‚ `cudaErrorInvalidValue`ï¼ˆå‚æ•°æ— æ•ˆï¼‰ã€‚

---

## **3. ä»£ç ç¤ºä¾‹**
### **(1) åŸºæœ¬ä½¿ç”¨**
```cpp
#include <cuda_runtime.h>
#include <iostream>

int main() {
    cudaStream_t stream;
    cudaStreamCreate(&stream);  // åˆ›å»º CUDA æµ

    int h_data[100], h_result[100];  // ä¸»æœºæ•°æ®
    int* d_data;  // è®¾å¤‡æŒ‡é’ˆ
    size_t size = 100 * sizeof(int);

    // åˆ†é…è®¾å¤‡å†…å­˜
    cudaMalloc((void**)&d_data, size);

    // å¼‚æ­¥æ‹·è´æ•°æ®åˆ°è®¾å¤‡
    cudaMemcpyAsync(d_data, h_data, size, cudaMemcpyHostToDevice, stream);

    // å¼‚æ­¥æ‹·è´æ•°æ®å›ä¸»æœº
    cudaMemcpyAsync(h_result, d_data, size, cudaMemcpyDeviceToHost, stream);

    // ç­‰å¾…æµä¸­ä»»åŠ¡å®Œæˆ
    cudaStreamSynchronize(stream);

    // é‡Šæ”¾èµ„æº
    cudaFree(d_data);
    cudaStreamDestroy(stream);

    std::cout << "Async memcpy completed!" << std::endl;
    return 0;
}
```
åœ¨ `cudaMemcpyAsync()` æ‰§è¡Œæ—¶ï¼ŒCPU **ä¸ä¼šç­‰å¾…** æ•°æ®æ‹·è´å®Œæˆï¼Œè€Œæ˜¯ç»§ç»­æ‰§è¡Œåç»­ä»£ç ã€‚åªæœ‰å½“ `cudaStreamSynchronize()` è¢«è°ƒç”¨æ—¶ï¼Œæ‰ä¼šé˜»å¡ CPU ç›´åˆ°æµä¸­çš„ä»»åŠ¡å®Œæˆã€‚

---

## **4. `cudaMemcpyAsync()` ä¸ `cudaMemcpy()` çš„åŒºåˆ«**
| ç‰¹æ€§               | `cudaMemcpy()`       | `cudaMemcpyAsync()`                                                |
| ------------------ | -------------------- | ------------------------------------------------------------------ |
| **åŒæ­¥/å¼‚æ­¥**      | **åŒæ­¥**ï¼ˆé˜»å¡ CPUï¼‰ | **å¼‚æ­¥**ï¼ˆä¸é˜»å¡ CPUï¼‰                                             |
| **é»˜è®¤æµ**         | ä½¿ç”¨é»˜è®¤æµ `0`       | å¯ä»¥æŒ‡å®šæµ                                                         |
| **è®¡ç®—ä¸æ‹·è´é‡å ** | âŒ **ä¸æ”¯æŒ**         | âœ… **æ”¯æŒ**ï¼ˆéœ€è¦ `cudaMemcpyAsync()` + `cudaStreamSynchronize()`ï¼‰ |
| **é€‚ç”¨åœºæ™¯**       | ç®€å•æ•°æ®æ‹·è´         | éœ€è¦ **å¹¶è¡Œæ‰§è¡Œè®¡ç®— & ä¼ è¾“** çš„æƒ…å†µ                                |

---

## **5. `cudaMemcpyAsync()` çš„é«˜çº§åº”ç”¨**
### **(1) è®¡ç®—ä¸æ•°æ®æ‹·è´é‡å **
`cudaMemcpyAsync()` çš„ä¸»è¦ä¼˜åŠ¿æ˜¯ **å¯ä»¥ä¸ Kernel å¹¶è¡Œæ‰§è¡Œ**ï¼Œæé«˜ GPU è®¡ç®—ååé‡ã€‚ä¾‹å¦‚ï¼š
```cpp
#include <cuda_runtime.h>
#include <iostream>

__global__ void kernel(int* d_data) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    d_data[idx] *= 2;
}

int main() {
    cudaStream_t stream;
    cudaStreamCreate(&stream);

    int h_data[100], h_result[100];
    int* d_data;
    size_t size = 100 * sizeof(int);

    cudaMalloc((void**)&d_data, size);

    // å¼‚æ­¥æ‹·è´æ•°æ®åˆ° GPU
    cudaMemcpyAsync(d_data, h_data, size, cudaMemcpyHostToDevice, stream);

    // åœ¨åŒä¸€æµä¸­å¯åŠ¨ Kernelï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
    kernel<<<1, 100, 0, stream>>>(d_data);

    // å¼‚æ­¥æ‹·è´ç»“æœå›ä¸»æœº
    cudaMemcpyAsync(h_result, d_data, size, cudaMemcpyDeviceToHost, stream);

    // ç­‰å¾…æµå®Œæˆ
    cudaStreamSynchronize(stream);

    cudaFree(d_data);
    cudaStreamDestroy(stream);
    return 0;
}
```
åœ¨è¿™é‡Œï¼š
1. **æ•°æ®æ‹·è´**ï¼ˆ`cudaMemcpyAsync()`ï¼‰
2. **è®¡ç®— Kernel æ‰§è¡Œ**ï¼ˆ`kernel<<<>>>`ï¼‰
3. **æ‹·è´ç»“æœå›ä¸»æœº**ï¼ˆ`cudaMemcpyAsync()`ï¼‰
éƒ½åœ¨ **åŒä¸€æµ**ï¼ˆ`stream`ï¼‰ä¸­æ‰§è¡Œï¼ŒCPU **ä¸ä¼šç­‰å¾…**ï¼Œè€Œæ˜¯ç»§ç»­æ‰§è¡Œåç»­ä»£ç ï¼Œæœ€ç»ˆ `cudaStreamSynchronize()` æ‰ä¼šé˜»å¡ CPUï¼Œç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚

---

### **(2) ä½¿ç”¨å¤šä¸ªæµå¹¶è¡Œæ‰§è¡Œä»»åŠ¡**
åœ¨å¤šæµï¼ˆMulti-streamï¼‰ç¯å¢ƒä¸‹ï¼Œå¤šä¸ª `cudaMemcpyAsync()` å¯ç”¨äº **å¹¶è¡Œæ•°æ®ä¼ è¾“**ï¼š
```cpp
cudaStream_t stream1, stream2;
cudaStreamCreate(&stream1);
cudaStreamCreate(&stream2);

cudaMemcpyAsync(d_data1, h_data1, size, cudaMemcpyHostToDevice, stream1);
cudaMemcpyAsync(d_data2, h_data2, size, cudaMemcpyHostToDevice, stream2);

cudaStreamSynchronize(stream1);
cudaStreamSynchronize(stream2);

cudaStreamDestroy(stream1);
cudaStreamDestroy(stream2);
```
- **æµ `stream1` ä¼ è¾“ `d_data1`ï¼Œæµ `stream2` ä¼ è¾“ `d_data2`ï¼Œä¸¤ä¸ªæ‹·è´ä»»åŠ¡å¯åŒæ—¶è¿›è¡Œã€‚**
- **å¦‚æœä¸ä½¿ç”¨æµï¼ŒCUDA ä»»åŠ¡å°†ä¼šä¸²è¡Œæ‰§è¡Œï¼Œä¸èƒ½å……åˆ†åˆ©ç”¨ GPU å¸¦å®½ã€‚**

---

## **6. `cudaMemcpyAsync()` å¯èƒ½çš„é”™è¯¯**
| é”™è¯¯ä»£ç                           | è¯´æ˜                                                                       |
| --------------------------------- | -------------------------------------------------------------------------- |
| `cudaErrorInvalidValue`           | å‚æ•°æ— æ•ˆï¼ˆå¦‚ `dst` æˆ– `src` ä¸ºç©ºæŒ‡é’ˆï¼‰                                     |
| `cudaErrorInvalidMemcpyDirection` | `cudaMemcpyKind` ä¸åŒ¹é…ï¼ˆå¦‚ `cudaMemcpyDeviceToHost` ä½† `dst` æ˜¯è®¾å¤‡æŒ‡é’ˆï¼‰ |
| `cudaErrorMemoryAllocation`       | è®¾å¤‡å†…å­˜ä¸è¶³                                                               |
| `cudaErrorIllegalAddress`         | è®¿é—®äº†æœªåˆ†é…æˆ–éæ³•çš„ GPU åœ°å€                                              |

---

## **7. `cudaMemcpyAsync()` é€‚ç”¨åœºæ™¯**
| åº”ç”¨åœºæ™¯               | è¯´æ˜                                          |
| ---------------------- | --------------------------------------------- |
| **æ•°æ®ä¼ è¾“ä¸è®¡ç®—å¹¶è¡Œ** | å¼‚æ­¥æ‹·è´ + Kernel è®¡ç®—ï¼Œå‡å°‘ CPU/GPU ç­‰å¾…æ—¶é—´ |
| **å¤šæµä»»åŠ¡è°ƒåº¦**       | åœ¨ä¸åŒæµä¸­æ‰§è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œæé«˜ GPU åˆ©ç”¨ç‡     |
| **æ‰¹é‡æ•°æ®å¤„ç†**       | é¢„åŠ è½½æ•°æ®ï¼Œæé«˜æ•°æ®ååé‡                    |

---

## **8. æ€»ç»“**
- `cudaMemcpyAsync()` **å¼‚æ­¥** è¿›è¡Œæ•°æ®æ‹·è´ï¼Œä¸ä¼šé˜»å¡ CPUã€‚
- éœ€è¦ **æŒ‡å®š CUDA æµ**ï¼Œå¦åˆ™é»˜è®¤ä½¿ç”¨ `0`ï¼ˆé»˜è®¤æµï¼‰ã€‚
- éœ€è¦ **é…åˆ `cudaStreamSynchronize()`** ç¡®ä¿æ•°æ®æ­£ç¡®æ€§ã€‚
- é€‚ç”¨äº **æ•°æ®ä¼ è¾“ + è®¡ç®—å¹¶è¡Œæ‰§è¡Œ**ï¼Œæé«˜ GPU è®¡ç®—ååé‡ã€‚

åˆç†ä½¿ç”¨ `cudaMemcpyAsync()` å¯ä»¥ **æå‡ CUDA åº”ç”¨çš„æ€§èƒ½**ï¼Œå°¤å…¶åœ¨ **æ·±åº¦å­¦ä¹ ã€ç§‘å­¦è®¡ç®—ã€å¤§è§„æ¨¡æ•°æ®å¤„ç†** ç­‰åœºæ™¯ä¸‹è¡¨ç°çªå‡ºï¼ğŸš€