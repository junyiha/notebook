---
category: LLM
date: 2025-05-03 10:00:00 +0800
layout: post
title: 大模型部署工具
tag: LLM
---
# 简介

+ 主流大模型部署工具

<!--more-->

# 概述

+ 常用的各种大模型本地部署工具和平台，按照不同性质可以分为以下几类和描述。
+ 其中最方便的人人都可以部署的三种傻瓜方式包括
  + Ollama
  + GPT4ALL
  + LM Studio
+ 都支持Windows MAC和Linux操作系统。

## 综合部署与服务管理平台

+ 这一类包括提供从模型训练到部署，管理和服务化的一站式解决方案的平台。这些工具通常支持模型的全生命周期管理，适用于需要高度集成和自动化的企业级部署。
+ 主要包括
  + Ollama
  + LM Studio
  + Ray Serve
  + GPT4ALL
  + vLLM
  + HuggingFace TGI
  + OpenLLM
  + LMDeploy
  + FastChat
  + LangChain

## 模型推理优化工具

+ 此类工具专注于提高模型的推理效率，通过硬件加速，算法优化等方式减少推理时间和资源消耗，适用于性能敏感的应用
+ 主要包括：
  + TensorRT-Llm
  + FasterTransformer
  + DeepSpeed-MII
  + CTranslate2
  + FlexFlow Server
  + MLC LLM
  + XInference

## 专用/特定任务模型部署框架

+ 这些工具通常针对特定的业务场景或模型类型进行优化，提供特定领域解决方案
+ 主要包括
  + H2OGPT
  + PrivateGPT
  + Text Generation
  + Inference
  + mlc-llm
  + QMoE

## 通用的机器学习和深度学习库

+ 这类库提供广泛的模型支持和开发工具，使开发者能够轻松的访问，训练和部署各种预训练模型
+ 主要包括
  + PyTorch Transformer
  + Hugging Face Transformers

## 特定语言实现

+ 针对特定编程语言优化的工具，通常提供了更好的性能和更深的系统集成能力，目前主要是C或C++语言
+ 主要包括：
  + llama.cpp
  + koboldcpp
  + PowerInfer
  + chatlm.cpp
  + qwen.cpp

# 引用

+ https://blog.csdn.net/l35633/article/details/138379452