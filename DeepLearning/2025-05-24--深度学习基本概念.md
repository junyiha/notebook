---
category: DeepLearning
date: 2025-05-24 09:00:00 +0800
layout: post
title: 深度学习基本概念
tag: AI部署
---
## 摘要

+ 深度学习基本概念
  + 上采样
  + 下采样
  + 卷积
  + 池化

<!--more-->

## 上采样

+ 上采样(upsampling)，又名放大图像，图像插值
+ 主要目的是放大原图像，从而可以显示在更高分辨率的显示设备上
+ 上采样有3中常见的方法：
  + 双线性插值(bilinear)
  + 反卷积(Transposed Convolution)
  + 反池化(Unpooling)

+ 原理：
  + 图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的差值算法插入新的元素。
  + 差值算法还包括了传统插值，基于边缘图像的插值，还有基于区域的图像插值

## 下采样

+ 下采样(subsampled)，又名降采样，缩小图像
+ 主要目的有
  + 使得图像符合显示区域的大小
  + 生成对应图像的缩略图
+ 其实下采样就是池化

+ 原理
  + 对于一副图像I尺寸为M*N，对其进行s倍下采样，即得到(M/s) * (N/s)尺寸的分辨率，当然，s应该是M和N的公约数才可以
  + 如果考虑是矩阵形式的图像，就是把原始图像s * s窗口内的图像变成一个像素，这个像素点的值就是窗口内所有像素的均值或者最大值(也就是Pooling池化操作等)
  + 采样曾是使用pooling的相关技术来实现的，目的就是来降低特征的维度并保留有效信息，一定程度上避免过拟合
  + 但是pooling的目的不仅仅是这些，他的目的是保持旋转，平移，伸缩不变性等。采样有最大值采样，平均值采样，求和区域采样和随机区域采样等
  + 池化也是这样的，例如最大值池化，平均值池化，随机池化，求和区域池化等。

## 卷积

+ 一次卷积运算指的是：当我们有一个过滤器，又称卷积核，也是矩阵。
+ 移动卷积核，将这个放款对应要处理的输入矩阵的一部分，位置一一对应相乘，然后把结果在相加到一个数

## 池化

+ 池化最直观的作用便是降维，常见的池化有最大池化，平均池化和随机池化；池化层不需要训练参数
  + 最大池化可以获取局部信息，可以更好保留纹理上的特征；如果不用观察物体在图片中的具体位置，只关心其是否出现，则使用最大池化效果较好
  + 平均池化往往能保留整体数据的特征，能凸出背景信息
  + 随机池化中元素值大的被选中的概率也大，但不是想最大池化总是取最大值，随机池化一方面最大化保证了Max值的取值，一方面又确保了不完全是max值起作用，造成过度失真；除此之外，其可以在一定程度上避免过拟合。