---
category: DeepLearning
date: 2025-05-13 09:00:00 +0800
layout: post
title: 图像标注
tag: AI部署
---
## 摘要

+ 图像标注

<!--more-->

## YOLO数据集格式

+ YOLO数据集的格式主要包括以下几个部分：
  + 图像文件：这是数据集中的图像文件，通常是 jpg 或 png 格式
  + 标注文件：这是一个文本文件，包含了每张图像中目标对象的类别和位置信息
  + 类别文件：这是一个文本文件，包含了数据集中所有目标对象的类别信息
+ 注：
  + 除扩展名外，标注文件的名称必须和图像的名称保持一致

## 标注文件格式

+ 主要包含了以下内容：
  + 每个目标对象的类别编号
  + 目标对象在图像中的中心位置(x, y)
  + 目标对象的宽度和高度(w, h)
+ x, y, w, h是小于1的浮点数。因为是经过对图像进行了归一化处理得到的值，也就是目标的真实x, w值 除以图像的宽度， y, h除以图像的高度。

## 类别文件格式

+ 主要包含了以下内容：
  + 每个类别的编号
  + 每个类别的名称

+ 一行代表一个类别，行号代表类别id(从0开始)。

## YOLO图像标注

+ YOLO(You Only Look Once)是一种实时目标检测系统，广泛应用于图像处理和计算机视觉领域。
+ 为了训练YOLO模型检测自定义目标，首先需要对图像进行标注。

## 使用LabelImg工具进行YOLO图像标注

+ 安装LabelImg工具
  + pip install labelimg

+ 使用LabelImg进行标注
  + 打开软件：输入 labelimg 命令启动
  + 打开文件夹：点击界面上的按钮，打开包含待标注图片的文件夹
  + 框选目标：使用鼠标框选目标区域，选择保存为YOLO格式(即将标记信息保存为txt格式)
  + 保存标注：点击 Save 按钮，将标注信息保存到指定文件夹。注意，保存的文件名要与原始图片文件名保持一致

## 训练模型

+ 准备数据集：新建训练集和验证集文件夹，分别命名为 train 和 val。每个文件夹中包含 images 和 labels 子文件夹，分别存放图片和对应的标注文件
+ 分配数据：将75%的标注图片和标签放入train文件夹，其余放入val文件夹
+ 创建yaml文件：根据需要创建一个yaml配置文件，指定训练和验证数据路径
+ 运行训练脚本：修改train.py中的参数，运行脚本开始训练。训练结果将存储在 runs/train/exp4/weights目录下

## yolo 目标检测 详细介绍数据标注基本原则

以下内容将从标注格式、标注原则与规范、标注流程及常见注意事项等方面，较为详尽地介绍用于 YOLO（You Only Look Once）目标检测的数据标注基本原则，帮助你在标注过程中保证高质量、高一致性，从而提升模型训练效果。

---

## 一、YOLO 数据标注的基本格式

在 YOLO 框架下，常见的数据标注格式为每张图片对应一个同名 `.txt` 文件，文本文件中的每一行表示一个目标实例，其字段顺序及含义如下：

```
<class_id> <x_center> <y_center> <width> <height>
```

* **class\_id**：目标类别的整数编码（从 0 开始计数），对应于训练时所指定的类别列表（例如 `person`→0, `car`→1 等）。
* **x\_center, y\_center, width, height**：所有坐标值均为相对于图片宽高归一化（Normalized）的浮点数，范围皆在 (0, 1) 之间。

  * `x_center = (xmin + xmax) / 2 / image_width`
  * `y_center = (ymin + ymax) / 2 / image_height`
  * `width  = (xmax - xmin) / image_width`
  * `height = (ymax - ymin) / image_height`

举例说明：若一张 1280×720 的图片中，检测框的左上角为 (xmin=320, ymin=180)，右下角为 (xmax=960, ymax=540)，则：

```
x_center = (320 + 960) / 2 / 1280 = 640/1280 = 0.5
y_center = (180 + 540) / 2 / 720  = 360/720  = 0.5
width    = (960 - 320)   / 1280    = 640/1280 = 0.5
height   = (540 - 180)   / 720     = 360/720  = 0.5
```

如果该目标类别对应的 `class_id` 为 3，则标注行写作：

```
3 0.5 0.5 0.5 0.5
```

**要点提醒**：

1. YOLO 采用的是中心点 + 宽高格式，方便网络预测。同时归一化能够提高对不同分辨率图片的兼容性。
2. 所有数值都需保留小数精度（一般保留小数点后 4\~6 位即可，但完全没要求只要确保精度一致即可），否则容易造成精度丢失导致模型定位不准确。

---

## 二、标注前需要统一的准备工作

在正式动手标注之前，应当先进行以下准备，以保证数据集标注的连贯性与准确性。

### 1. 确定类别列表（Class List）

* **事先定义所有目标类别的编号和名称**。例如如果要检测行人、汽车、自行车，就可以约定：

  ```
  0 person
  1 car
  2 bicycle
  ```
* **类别命名要具有可读性且互不重复**，例如不要用 `car1`、`car2` 这种容易混淆的命名，如果场景中需要区分轿车（sedan）、货车（truck）等，应当直接用“sedan”“truck”进行区分，而不是在一个“car”类别中再通过后缀区分。
* 在后续标注时，标注工具与训练脚本需要引用同样的类别列表文件（如 `obj.names` 或 `classes.txt`），务必保证与实际标注文件中 `class_id` 一一对应，否则网络训练会找不到对应的类别或产生混乱。

### 2. 选择并统一标注工具

常用标注工具有：

* **LabelImg**（开源、界面简单）：可以导出多种格式，包括 VOC（XML）、COCO（JSON）、YOLO（TXT）。
* **Labelme**（支持多边形标注、灵活度高）：也可以输出 COCO、VOC、YOLO 等格式，但需要手动配置转换脚本。
* **Roboflow Annotation**、**CVAT**（团队协作较方便）
* **MakeSense.ai**、**Supervise.ly** 等在线工具

标注前一定要在工具中做好以下设置：

1. **导出格式**：选择 YOLO TXT 格式，或 VOC/COCO 格式后再通过脚本统一转换成 YOLO 格式。
2. **图像尺寸信息**：有些工具默认会在标签文件里写明图像原始尺寸，有些不记录尺寸，这就要求后续脚本读入图片时一定要动态获取其宽高，否则归一化会出错。
3. **坐标显示方式**：确保用的是左上角坐标 + 右下角坐标进行拖框标注，而非绕过中点或边长等模式，因为部分工具默认用的是这种方式，需要确认并开启“标注为：YOLO Darknet 格式”或类似选项，以避免先前标注纠错。

---

## 三、标注时的基本原则与规范

针对 YOLO 目标检测，需要遵守以下几个核心原则，以保证标注数据质量高且具有可用性。

### 1. 边界框（Bounding Box）的准确性

* **精确包围目标**：标注框应尽量贴合目标物体且包含其全部边缘，但不应过多包含背景。过宽的框会干扰模型学习到与目标无关的背景特征；过窄的框则会丢失目标部分信息。
* **排除无关物体与遮挡区**：如果目标部分被遮挡，例如行人被挡住了一只手臂，要判断是否仍然可识别。一般原则是：**超过 50% 被遮挡，可不标注**；若仅部分遮挡且能大致判断物体轮廓，则尽量用框包住全体可见区域。
* **多视角与小目标处理**：

  * 对于小目标（bounding box 占图片面积 < 1%），仍然要做标注，但需格外注意归一化之后的宽高是否大于极小值（如 <0.01）。如果某些小目标框过小，可能模型不好学习，可酌情扩大框，使其至少能覆盖目标中心。
  * 对于目标与背景相近的情况，一定要仔细放大预览，避免出现“利用背景线索去检测”的情况。

### 2. 类别分配要准确、一致

* **尽量遵循“单一物体归为一个类别”原则**，例如“交通灯”与“红绿灯”不要混用。如果场景有不同种类的信号灯，则应分开定义标签。
* **对于嵌套目标或成组目标**：

  * 如果检测的是“一只猫”，但图里有一群猫，需区分单只个体，就要标注每个猫的框；如果业务仅需要检测“猫”的存在，可以只标注一个大框包住整群，但务必在标注说明里写明“仅检测整体群体，非单独个体”。
  * 如果检测“桌面上的物品”，要明确是否需要同时标注桌子（table）与其上的物品（如手机、笔）；如果只是物品检测，就不要标注桌子本身。

### 3. 坐标归一化与数据一致性

* **严格按照 “相对坐标 <0,1>” 规范** 进行归一化。每次标注完一个框，务必确认 `x_center`, `y_center`, `width`, `height` 都在 (0, 1) 区间内。
* **不要让标注框超出图像边界**。如果框部分位于图像外，就需要裁剪到图像范围内，或者直接删除该框再重新标。
* **同一张图每个目标只能标注一次**。不要给同一个目标标注多个高度重叠的框；如果相邻框重叠率（IoU）超过 0.8，要确认是否为同一个物体的重复标注。若训练中需要进行“锚框（anchors）优化”、“NMS（Non-Maximum Suppression）”等，可在后续自动化阶段处理，标注阶段应降低重复。

### 4. 模糊、遮挡与难例的处理

1. **模糊目标**

   * 如果目标被轻微模糊，但仍可辨识（例如轻微运动模糊），应依旧标注，理由是：模型能从轮廓与纹理信息中学习。
   * 如果目标严重模糊到几乎看不清，如仅留下一团色块、无法确定类别，就可以选择不标注，或者打 “难例”，在后续训练时决定是否使用（做“困难样本挖掘”）。

2. **遮挡目标**

   * **少量遮挡（<50%）**：仍然标注完整目标框。
   * **大面积遮挡（>50%）**：视业务场景决定：

     * 若业务对遮挡目标仍需检测，可标注剩余可见部分，同时在内部注释文件（如 `labels.txt`）中说明“该目标被遮挡，仅标注可见部分”。
     * 若大面积遮挡到不可识别，则跳过该目标。

3. **“难以界定”目标**

   * 例如阴影、反光、透明玻璃后物体、镜中倒影等。这些时效性与可见度都很差，可能对模型训练产生干扰。一般建议不予标注，或者为其添加“难例”类别标签（例如 `ignore` 类别），并在训练阶段设置损失函数忽略这部分。

---

## 四、具体标注流程与步骤

下面给出一个推荐的通用标注流程，帮助你系统化地组织标注工作。

1. **图像预处理与筛选**

   * 将所有要标注的图像按统一尺寸（如 1280×720、1920×1080 等）或固定纵横比进行归一化处理，便于后续归一化坐标计算与模型训练。
   * 确保图像的方向（横/竖）一致，若某些图为旋转状态，请先复位。
   * 按照场景或拍摄时间、拍摄点等信息进行分组分类，便于后续训练集/验证集/测试集划分。

2. **建立类别列表文件**

   * 创建一个文本文件（例如 `classes.txt`），每行写一个类别名称，顺序即代表对应的 `class_id`。
   * 确保类名与标注工具配置一致。

3. **使用标注工具进行初始标注**

   * 在标注软件中加载 图片 目录，并加载 `classes.txt` 作为类别参考。
   * 对每张图片中的目标进行拖框标注，看见一个目标就框一个框，框住目标最外层可视边界。
   * 标注时保持**手动校验**：

     * 标注框边线要紧贴目标，不要留太多空隙；
     * 若有多个目标，确保相互之间不混淆，例如两个行人靠得很近时，需要在放大状态下逐个框选，避免漏标或重叠标注。
   * 对于每个标注实例，都要检查其是否符合“完整”、“可识别”、“符合类别定义”三大核心要求。

4. **初步质量自检**

   * 在标注完成一套图像后，先抽取一部分标注文件，用预览脚本可视化标注框效果（如把归一化坐标转换回像素坐标，以及在图像上画出矩形框）。
   * 重点检查：

     * **坐标是否在 \[0, 1] 范围**
     * **标注框是否正确覆盖目标**
     * **是否有遗漏与误标**
     * **相同物体是否标注两次或多次**
   * 通过可视化脚本（例如使用 OpenCV 或 PIL）把标注结果叠加到图片上，目测检查 5%\~10% 的数据，看是否存在明显偏差。

5. **团队或第三方复核**

   * 如果标注量较大（如几千张以上），建议进行二次审核，由另一个标注人员检查。可以在标注工具中开启“审核模式”，由第二人只对已标注内容进行“删除/修改”操作。
   * 如果有预算，也可考虑使用众包平台（例如 Amazon Mechanical Turk、Supervise.ly 团队版）进行额外复核，并将结果与初次标注对比，筛查一致性差异较大的样本进行重点校正。

6. **生成最终训练/验证/测试集清单**

   * 按照一定比例（例如 80% 训练 + 10% 验证 + 10% 测试）将图像文件均匀分配，并把对应的图片路径与标注路径写入相应的列表文件（例如 `train.txt`、`val.txt`、`test.txt`）。
   * **注意**：如果是场景视频中截帧得到的图片，可能相邻两帧非常相似，不应将相邻帧分到训练集与测试集，以免出现“数据泄露”导致模型泛化能力被高估。

---

## 五、标注过程中的常见注意事项与建议

### 1. 保持标注一致性

* **统一标注规范**：建议团队内部出一份“标注手册”，详细描述“如何框”、“何时不框”、“如何处理特殊情况”，让所有标注人员都参考同一份手册。
* **定期对齐沟通**：标注过程中出现争议样本时，团队应定期开会讨论并形成最终裁定，更新到标注手册中，避免重复走弯路。

### 2. 特殊场景下的标注策略

1. **遮挡与重叠**

   * 针对遮挡严重的场景，可在标注时额外添加一个“遮挡程度”属性（例如轻度、中度、重度），便于后续分析或做难例挖掘。
   * 当两个目标相互遮挡时，尽量“各自框起可见部分”，不要将两者合并为一个大框，除非业务要求只检测整体。

2. **分辨率与规模差异**

   * 如果图片中既有大目标（占整图 50% 以上）又有小目标（占整图 <1%），建议在标注时采用“分场景标注”或“多尺度训练”策略，即在后续训练中对小目标进行数据增强（如放大、拼接）以缓解样本不平衡。

3. **运动模糊与低光照**

   * 某些场景下帧间运动较快，导致目标模糊；或者夜间光照不足导致较多噪点。在这种情况下，如果目标轮廓仍可辨识，应尽量标注。若完全无法分辨，就跳过该框。
   * 如果该类别在后续模型中表现很差，可考虑做“数据增强”或“生成式增强”补充这类样本。

### 3. 避免过标或少标

* **过标**：给同一个物体框多个稍微有差异的框，或者把背景中充当“对象”的阴影、反光等误标为目标。这样会干扰模型，不仅降低准确率，还会浪费标注成本。
* **少标**：漏标图片中存在但未被标注的目标，例如标注人员疲劳或漏看，会导致训练时“负样本”误导模型，使模型在推理时漏检或误判。
* **解决策略**：可采用“双人交叉标注 + 自动对比脚本检测”手段。例如，一人标注后，运行一个后处理脚本检测“一个类别在一张图上标注数量是否异常”（若场景中行人通常是 1\~3 个，但这张图标注 10 个，需要人工复核）。或采用简单的 “标注密度” 统计，比如统计所有图片每个类别平均标注数，若某张图与平均相差太多则拉入复核队列。

### 4. 记录与版本管理

* **在标注文件夹外单独维护标注日志**：记录每天每个标注人员标注了多少张、哪些特殊情况、哪些样本做了修改。
* **使用版本控制（Git、SVN 等）**：将标注结果（`.txt` 文件）纳入版本管理，并在重要里程碑（如“完成 50% 标注”、“完成 100% 标注”）打标签，方便后续追溯。
* **定期备份**：因为标注数据往往量大且谨慎性高，一旦丢失或误删修复困难。可选用云盘、NAS 等工具进行每日增量备份。

---

## 六、标注完成后的验证与常用工具

### 1. 可视化验证脚本

即使在标注工具中可以预览，也建议写一个简单的可视化脚本对整批标注实行 **批量抽样** 检查。示例伪代码（Python + OpenCV）：

```python
import os
import cv2

image_dir = "images/"
label_dir = "labels/"

for img_name in os.listdir(image_dir):
    img_path = os.path.join(image_dir, img_name)
    lbl_path = os.path.join(label_dir, img_name.replace(".jpg", ".txt"))
    img = cv2.imread(img_path)
    h, w, _ = img.shape
    
    with open(lbl_path, 'r') as f:
        for line in f.readlines():
            cls, x_c, y_c, box_w, box_h = map(float, line.strip().split())
            x_c *= w; y_c *= h
            box_w *= w; box_h *= h
            x1 = int(x_c - box_w/2)
            y1 = int(y_c - box_h/2)
            x2 = int(x_c + box_w/2)
            y2 = int(y_c + box_h/2)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)
            cv2.putText(img, str(int(cls)), (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 
                        0.5, (0,255,0), 1)
    cv2.imshow("ann", img)
    key = cv2.waitKey(0)
    if key == ord('q'):
        break
```

通过此脚本，你可以直观地看到标注框与原图是否吻合，也能及时发现归一化坐标异常或标错类别的情况。

### 2. 自动一致性检查脚本

除了可视化，还可以写脚本进行以下自动化检查：

* **坐标越界**：检查 `x_center - width/2 < 0`、`x_center + width/2 > 1`、`y_center - height/2 < 0`、`y_center + height/2 > 1` 等。
* **零面积框**：检查宽或高是否为 0。
* **异常比例**：检查单一样本中某一类框数量过多（与平均值差距大）。
* **重复框**：可以根据 IoU 阈值（如 0.9）检测同类别两个框是否高度重叠，如果是则提示人工复核。
* **缺少标注**：如果某些图片中按照场景常理应有目标但标注数为 0，可以列入复核列表（如人脸检测，如果某些街景图片中没有标任何人脸则要检查是否漏标）。

### 3. 数据增强与后续处理

标注只是第一步，还需要考虑：

* **数据增强**：随机翻转、缩放、亮度/对比度调整等，需要同步对标注框做变换。YOLO 很多开源框架都内置了数据增强功能，如果手动做增强需要编写脚本实时更新标注。
* **锚框（Anchor）聚类**：在 YOLOv3、YOLOv5 等版本里，需要根据真实标注框尺寸做 k-means++ 聚类，算出最优锚框配置，提高召回效果。
* **划分训练/验证/测试集**：在标注后要仔细设计抽样比例，并确保每个划分中各类别样本分布均匀、场景多样，否则会影响模型泛化能力。

---

## 七、总结与补充建议

1. **标注质量决定模型上限**
   高质量的标注不仅要框得准确，还要在 **类别分配、遮挡处理、归一化一致性** 等方面做到规范化。随意、含糊或不一致的标注会导致模型训练效果大打折扣。

2. **标注效率与标注准确度的平衡**

   * 对同一批图像，先做一次粗略标注（快速划框），然后再做一次精细复核。这样既保证了进度，又能兼顾准确性。
   * 标注速度太快容易疏漏，太慢又会导致成本过高。一般建议每小时标注 50\~80 张中等分辨率图（如果是多类别、复杂场景可能更低），并留出 20%\~30% 的时间进行复核。

3. **团队协作与沟通机制**

   * 采用在线协作平台，可以实时查看标注进度、分配任务。
   * 建立 **标注问题反馈机制**：如微信群/Slack 群里设立“标注疑问”频道，标注人员遇到不确定样本及时举例讨论、更新“标注手册”后统一执行。

4. **迭代与优化**

   * 在第一次训练后，往往会发现某些类别误检率高或漏检率高针对这些问题样本进行二次标注或补充样本，逐步提升检测效果。
   * 定期检查新数据的分布是否与已标注数据分布一致，否则需要做 **领域自适应** 或在原有标注规范上做调整。

---

通过以上从“标注格式”、“前期准备”、“标注原则”、“标注流程”、“复核与验证”、“后续处理”到“总结建议” 的系统化介绍，希望你对如何为 YOLO 目标检测构建高质量的数据集有一个较为清晰且全面的认识。标注过程是整个目标检测任务中耗时且极其关键的一环，只有投入足够的时间对标注规范严格把关，才能为后续模型训练打下坚实基础。祝你标注顺利、检测性能节节提升！
